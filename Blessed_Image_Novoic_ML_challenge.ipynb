{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blessed Image Novoic ML challenge",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrFlygerian/portfolio-for-data-science/blob/master/Blessed_Image_Novoic_ML_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoL3Xe4N-yMS"
      },
      "source": [
        "___This is Blessed Chianumba's attempt at the Novoic ML challenge. An ongoing project.___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOHLZHtggQtk"
      },
      "source": [
        "<a href=\"https://novoic.com\"><img src=\"https://assets.novoic.com/logo_320px.png\" alt=\"Novoic logo\" width=\"160\"/></a>\n",
        "\n",
        "# Novoic ML challenge – image data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlll6t_8M5fy"
      },
      "source": [
        "## Introduction\n",
        "Welcome to the Novoic ML challenge!\n",
        "\n",
        "This is an open-ended ML challenge to help us identify exceptional researchers and engineers. The guidance below describes an open-source dataset that you can use to demonstrate your research skills, creativity, coding ability, scientific communication or anything else you think is important to the role.\n",
        "\n",
        "We recommend you spend around three hours on this (more or less if you wish), which you do not have to do in one go. Please make use of any resources you like. Feel free to shoot us an email with any questions that you might have!\n",
        "\n",
        "This is the image version of the challenge. Also available are text and audio versions. You can access all three from [this GitHub repo](https://github.com/novoic/ml-challenge).\n",
        "\n",
        "Best of luck – we're looking forward to seeing what you can do!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUJZyzMB_2TA"
      },
      "source": [
        "## Prepare the data\n",
        "Copy the dataset to a local directory – this should take around 10 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaRNBDz4nN1t"
      },
      "source": [
        "%%time\n",
        "\n",
        "!mkdir -p data\n",
        "!gsutil -m cp -r gs://novoic-ml-challenge-image-data/* ./data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpJ7NOCXkCKs"
      },
      "source": [
        "## Data description\n",
        "\n",
        "The data comprises 17,125 images in jpg format. Each image is of a realistic scene typically containing a number of objects.\n",
        "\n",
        "There are 20 object classes of interest: aeroplane, bicycle, bird, boat, bottle, bus, car, cat, chair, cow, dining table, dog, horse, motorbike, person, potted plant, sheep, sofa, train, TV monitor. \n",
        "\n",
        "Each image is labelled with one of three numbers for each object class:\n",
        "- -1 (no objects of this class feature in the image)\n",
        "- 1 (at least one object of this class features in the image)\n",
        "- 0 (at least one object of this class features in the image but they are all difficult to recognise)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muZyXMc8rbAK"
      },
      "source": [
        "import IPython \n",
        "IPython.display.Image(filename='data/images/2012_004258.jpg') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ey4KqN1uBqN"
      },
      "source": [
        "IPython.display.Image(filename='data/images/2008_007739.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeYkLol_rZoT"
      },
      "source": [
        "Each object class file (e.g. `aeroplane.txt`) contains the name of the image without the extension (e.g. `2008_007739`) followed by a space and then the class label (e.g. `-1`).\n",
        "\n",
        "For more information about the dataset, see its `README.md`.\n",
        "\n",
        "Directory structure:\n",
        "```\n",
        "data/\n",
        "├── images/         # dir for jpg files\n",
        "├── aeroplane.txt   # aeroplane object class labels\n",
        "├── bicycle.txt     # bicycle object class labels\n",
        "├── bird.txt        # bird object class labels\n",
        "├── boat.txt        # boat object class labels\n",
        "├── bottle.txt      # bottle object class labels\n",
        "├── bus.txt         # bus object class labels\n",
        "├── car.txt         # car object class labels\n",
        "├── cat.txt         # cat object class labels\n",
        "├── chair.txt       # chair object class labels\n",
        "├── cow.txt         # cow object class labels\n",
        "├── diningtable.txt # dining table object class labels\n",
        "├── dog.txt         # dog object class labels\n",
        "├── horse.txt       # horse object class labels\n",
        "├── motorbike.txt   # motorbike object class labels\n",
        "├── person.txt      # person object class labels\n",
        "├── pottedplant.txt # potted plant object class labels\n",
        "├── sheep.txt       # sheep object class labels\n",
        "├── sofa.txt        # sofa object class labels\n",
        "├── train.txt       # train object class labels\n",
        "├── tvmonitor.txt   # TV monitor object class labels\n",
        "├── LICENSE\n",
        "└── README.md\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7x5PwDaFDdy"
      },
      "source": [
        "## The challenge\n",
        "This is an open-ended challenge and we want to witness your creativity. Some obvious suggestions:\n",
        "- Data exploration/visualization\n",
        "- Binary/multiclass classification\n",
        "- Anomaly detection\n",
        "- Unsupervised clustering\n",
        "- Model explainability\n",
        "\n",
        "You're welcome to explore one or more of these topics, or do something entirely different.\n",
        "\n",
        "Create, iterate on, and validate your work in this notebook, using any packages of your choosing.\n",
        "\n",
        "**You can access a GPU via `Runtime -> Change runtime type` in the toolbar.**\n",
        "\n",
        "## Submission instructions\n",
        "Once you're done, send us this `.ipynb` notebook (or a link to it hosted on Google Drive/GitHub with appropriate permissions) by email, ensuring that outputs from cells (text, plots etc) are preserved.\n",
        "\n",
        "If you haven't applied already, make sure you submit an application first through our [job board](https://novoic.com/careers/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXJdZxNrK008"
      },
      "source": [
        "## Your submission\n",
        "The below sets up TensorFlow as an example but feel free to use any framework you like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8PoDC7xLkU4"
      },
      "source": [
        "Take the wheel!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7A3vYU3LRz_"
      },
      "source": [
        "# The default TensorFlow version on Colab is 1.x. Uncomment the below to use TensorFlow 2.x instead.\n",
        "# %tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_-0bsdzK6sy"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o42lURRnht3M"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJX9c372hs3J"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.applications\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Input\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.models import load_model\n",
        "\n",
        "import pickle\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIjIMzkciF__"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-okt_f5QP_y"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeGdeDNZhs7Q"
      },
      "source": [
        "DATA_DIR = '/content/data/'\n",
        "IMAGE_DIR = '/content/data/images/'\n",
        "LOG_DIR = 'tb_novoic_image_logs'\n",
        "\n",
        "TXT_FNAMES = glob.glob(DATA_DIR + '*.txt')\n",
        "\n",
        "EXPORTED_DF_FNAME = 'Novoic_imgs_df'\n",
        "VALID_SIZE = 100\n",
        "BATCH_SIZE = 100  # Major factor in if the models actually run; larger batch sizes result in OOM error as resource runs out\n",
        "EPOCHS = 50\n",
        "IMG_SIZE = 256\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m98UO4dwGBj"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3GkrfG1_e-y"
      },
      "source": [
        "## Data Preperation\n",
        "\n",
        "Our data is in an odd format atm. Let's change it in to a form that keras can understand for augmentation and training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byE_GWIxmmCf"
      },
      "source": [
        "sample_df = pd.read_csv(TXT_FNAMES[0], header=None, sep='\\s+' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaQ8TDccm0x_"
      },
      "source": [
        "sample_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gHRh6-Vl1-a"
      },
      "source": [
        "frames = []\n",
        "\n",
        "for name in TXT_FNAMES:\n",
        "    frames.append(pd.read_csv(name, header=None, sep='\\s+' ))\n",
        "\n",
        "df = pd.concat(frames, axis=1)\n",
        "\n",
        "cols = [re.findall(r'[ \\w-]+?(?=\\.)',fname) for fname in TXT_FNAMES]\n",
        "cols = [item for fname in cols for item in fname]\n",
        "\n",
        "df.index=df.iloc[:,0]\n",
        "df.index = df.index +'.jpg'\n",
        "df.index.name = 'image_file_path'\n",
        "df = df.drop(columns=0)\n",
        "df.columns = cols\n",
        "df.reset_index(inplace=True)\n",
        "df[df.columns[1:]]= df[df.columns[1:]].astype(float)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78G6rTmteHdQ"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKTlkOEEolWt"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jnoEN2Mecx_"
      },
      "source": [
        "## Image modelling with Keras\n",
        "\n",
        "We'll use keras to create and train our models with imagenet weights for transfer learning. Tensorboard will help us to see how our models are doing, and Early Stopping will terminate our training if the validation score doesn't imprve after a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFZUy0Ms0SIN"
      },
      "source": [
        "\"\"\"Only required if there is a dedicated GPU available\"\"\"\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config = ConfigProto(device_count = {'GPU': 0})\n",
        "\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NETNPjwr0SIQ"
      },
      "source": [
        "# reset Keras Session\n",
        "def reset_keras():\n",
        "    sess = tf.compat.v1.keras.backend.get_session()\n",
        "    tf.compat.v1.keras.backend.clear_session()\n",
        "    sess.close()\n",
        "    sess = tf.compat.v1.keras.backend.get_session()\n",
        "\n",
        "    try:\n",
        "        del classifier # this is from global space - change this as you need\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # use the same config as you used to create the session\n",
        "    config = tf.compat.v1.ConfigProto()\n",
        "    #config = ConfigProto(device_count = {'GPU': 0})\n",
        "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
        "    config.gpu_options.visible_device_list = \"0\"\n",
        "    tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
        "    \n",
        "reset_keras()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eabBjhwWVZ4L"
      },
      "source": [
        "# Split original dataframe\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df[:-VALID_SIZE], test_size = 0.25)\n",
        "print('train data shape:', train.shape, '\\ntest data shape:', test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzHX4lYcVlWs"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boujTlynVgOe"
      },
      "source": [
        "train_set=datagen.flow_from_dataframe(\n",
        "    dataframe=train,\n",
        "    directory=IMAGE_DIR,  \n",
        "    x_col='image_file_path', \n",
        "    y_col=train.columns[1:],\n",
        "    batch_size=BATCH_SIZE, \n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"raw\",\n",
        "    target_size=(IMG_SIZE,IMG_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdpoGWyxgt0N"
      },
      "source": [
        "test_set = datagen.flow_from_dataframe(\n",
        "    dataframe=test,\n",
        "    directory=IMAGE_DIR,\n",
        "    x_col='image_file_path',\n",
        "    y_col=test.columns[1:],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode='raw',\n",
        "    target_size=(IMG_SIZE,IMG_SIZE)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsvWoSa_ee15"
      },
      "source": [
        "output_layer = len(train.columns[1:])\n",
        "print(output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k79nkrAcwuSK"
      },
      "source": [
        "# functions for building models, running models and custom callbacks\n",
        "\n",
        "# Buidling models\n",
        "def build_model(architecture):\n",
        "  model = Sequential()\n",
        "\n",
        "  if architecture == 'VGG19':\n",
        "    print('Using VGG19')\n",
        "    model.add(keras.applications.vgg19.VGG19(weights='imagenet', include_top=False,\n",
        "                                             input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='input')))\n",
        "    model.add(Flatten(name='flatten'))\n",
        "    model.add(Dense(1000, activation='relu', name='fc1'))\n",
        "    model.add(Dense(1000, activation='relu', name='fc2'))\n",
        "    model.add(Dense(output_layer, activation='softmax', name='predictions'))\n",
        "\n",
        "  elif architecture == 'InceptionResNetV2':\n",
        "    print('Using InceptionResNetV2')\n",
        "    model.add(tf.keras.applications.InceptionResNetV2(weights='imagenet', include_top=False,\n",
        "                                                      input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='input')))\n",
        "    model.add(tf.keras.layers.Conv2D(filters=3000, kernel_size=(2,2),\n",
        "                                     kernel_initializer='he_uniform', padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.AveragePooling2D(pool_size=2, strides=2))\n",
        "    model.add(Flatten(name='flatten'))\n",
        "    model.add(Dense(output_layer, activation='softmax', name='predictions'))\n",
        "\n",
        "  else:\n",
        "    print('Using ResNet50')\n",
        "    model.add(keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False,\n",
        "                                                   input_tensor=Input(shape=(IMG_SIZE,IMG_SIZE, 3), name='input')))\n",
        "    model.add(tf.keras.layers.Conv2D(filters=3000, kernel_size=(2,2),\n",
        "                                     kernel_initializer='he_uniform', padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.AveragePooling2D(pool_size=2, strides=2))\n",
        "    model.add(Flatten(name='flatten'))\n",
        "    model.add(Dense(output_layer, activation='softmax', name='predictions'))\n",
        "    \n",
        "  model.compile(optimizer=keras.optimizers.RMSprop(lr=1e-4), loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.Precision()])\n",
        "    \n",
        "    \n",
        "  return model\n",
        "\n",
        "# custom callback(s)\n",
        "def get_TB(name):\n",
        "    \n",
        "\n",
        "    folder_name = f'{name}_logs'\n",
        "    dir_paths = os.path.join(LOG_DIR, folder_name)\n",
        "\n",
        "    try:\n",
        "        os.makedirs(dir_paths)\n",
        "    except OSError as err:\n",
        "        print (err.strerror)\n",
        "    else:\n",
        "        print ('made directory')\n",
        "\n",
        "    return TensorBoard(log_dir=dir_paths, profile_batch=2, write_graph=True,\n",
        "                       histogram_freq=1, embeddings_freq=1 )\n",
        "\n",
        "\n",
        "# running models\n",
        "def run_model(model, name):\n",
        "  es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=7)\n",
        "  tb = TensorBoard(log_dir=f'./{name}_logs', profile_batch=2, embeddings_freq=1, histogram_freq=1)\n",
        "\n",
        "  history = model.fit(x = train_set, validation_data = test_set, epochs = EPOCHS, callbacks=[es, get_TB(name)])\n",
        "  model.save(f'test_{name}.h5')\n",
        "  with open(f'test_history_{name}', 'wb') as file_pi:\n",
        "        pickle.dump(history.history, file_pi)\n",
        "  \n",
        "  model.summary()\n",
        "\n",
        "  return history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOwOLUON1xx7"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Build and run InceptionResNetV2 Model\n",
        "Inception_ResNet_model = build_model('InceptionResNetV2')\n",
        "IR_history = run_model(Inception_ResNet_model, 'IR_model')\n",
        "\n",
        "# Build and run VGG19 Model\n",
        "VGG19_model = build_model('VGG19')\n",
        "VGG19_history = run_model(VGG19_model, 'VGG19_model')\n",
        "\n",
        "# Build and run ResNet Model\n",
        "ResNet_model = build_model('ResNet')\n",
        "ResNet_history = run_model(ResNet_model, 'ResNet_model')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDLK9fdGfRBL"
      },
      "source": [
        "####_Visualise training_ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YKq3njke-jY"
      },
      "source": [
        "# Get a visual on the model performance and structure\n",
        "\n",
        "# %load_ext tensorboard\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /tb_novoic_image_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSThCiFzZrvA"
      },
      "source": [
        "#### _Retaining weights and data_ \n",
        "\n",
        "Let's keep this information as it took us hours to get it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDi1fwg0yI8O"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1fxd2zNQrJa"
      },
      "source": [
        "# save data, models, history and log files for resuse (model runtime is a major bottle neck)\n",
        "\n",
        "%cp -at \"/gdrive/My Drive/Colab Notebooks/Novoic Image Challenge files\"  \"data/\"\n",
        "\n",
        "%cp -at \"/gdrive/My Drive/Colab Notebooks/Novoic Image Challenge files\"  \"test_ResNet_model.h5\"\n",
        "%cp -at \"/gdrive/My Drive/Colab Notebooks/Novoic Image Challenge files\"  \"test_IR_model.h5\"\n",
        "%cp -at \"/gdrive/My Drive/Colab Notebooks/Novoic Image Challenge files\"  \"test_VGG19_model.h5\"\n",
        "\n",
        "%cp -at \"/gdrive/My Drive/Colab Notebooks/Novoic Image Challenge files\"  \"tb_novoic_image_logs/\"\n",
        "\n",
        "%cp -at \"/gdrive/My Drive/Colab Notebooks/Novoic Image Challenge files\"  \"test_history_IR_model\"\n",
        "%cp -at \"/gdrive/My Drive/Colab Notebooks/Novoic Image Challenge files\"  \"test_history_ResNet_model\"\n",
        "%cp -at \"/gdrive/My Drive/Colab Notebooks/Novoic Image Challenge files\"  \"test_history_VGG19_model\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LraZ73tfHWI-"
      },
      "source": [
        "## Making Predictions\n",
        "\n",
        "Lets see how well our models do on data that hasn't already been seen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9sBekeV9KTg"
      },
      "source": [
        "validation = df.iloc[-VALID_SIZE:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoPw-92_6E3Z"
      },
      "source": [
        "# Retrieve holdout set for real validation\n",
        "\n",
        "holdout_set = datagen.flow_from_dataframe(\n",
        "    dataframe=validation,\n",
        "    directory=IMAGE_DIR,\n",
        "    x_col='image_file_path',\n",
        "    y_col=test.columns[1:],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode='raw',\n",
        "    target_size=(IMG_SIZE,IMG_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn5MF875J6rQ"
      },
      "source": [
        "# display a few images \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def process(filename: str=None) -> None:\n",
        "    \"\"\"\n",
        "    View multiple images stored in files, stacking vertically\n",
        "\n",
        "    Arguments:\n",
        "        filename: str - path to filename containing image\n",
        "    \"\"\"\n",
        "    image = mpimg.imread(filename)\n",
        "    plt.figure()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "\n",
        "print('first 3 images of the holdout set')\n",
        "for i in range(0,3):\n",
        "    process(IMAGE_DIR + validation.iloc[i,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meRaBWCRDp4w"
      },
      "source": [
        "### Measure accuracy of models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nLuXvlr6__3"
      },
      "source": [
        "# function for testing model (validation data should be a var too)\n",
        "def test_model(model_file_path, name, validation_dataset):\n",
        "  model = load_model(model_file_path)\n",
        "\n",
        "  pred_labels = np.argmax(model.predict(validation_dataset), axis = 1)\n",
        "  pred_classes = [cols[i] for i in pred_labels]\n",
        "  print('Predicted dominant image feature for the first 3 images: ', pred_classes[:3])\n",
        "  acca = sum(np.equal(true_labels, pred_labels)) / len(true_labels)\n",
        "  print(f\"Accuracy of model {name}: {acca:.0%} \" )\n",
        "\n",
        "  return acca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0gI8KZQ3CXt"
      },
      "source": [
        "# function for getting model history\n",
        "def get_model_history(history_file_path):\n",
        "  with open(history_file_path, 'rb') as file:\n",
        "    history=pickle.load(file)\n",
        "  \n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz9kIMxH_NGo"
      },
      "source": [
        "true_labels = np.argmax(holdout_set.labels, axis = 1)\n",
        "true_classes = [cols[i] for i in true_labels]\n",
        "\n",
        "print('Most dominant image feature for the first 3 images: ', true_classes[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S454jyXJ6_9e"
      },
      "source": [
        "ResNet_acca = test_model('test_ResNet_model.h5','ResNet', holdout_set)\n",
        "VGG19_acca = test_model('test_VGG19_model.h5', 'VGG19', holdout_set)\n",
        "IR_acca = test_model('test_IR_model.h5', 'InceptionResNet',holdout_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY4s-Wmy3CSi"
      },
      "source": [
        "IR_history = get_model_history('/content/test_history_IR_model')\n",
        "VGG19_history = get_model_history('/content/test_history_VGG19_model')\n",
        "ResNet_history = get_model_history('/content/test_history_ResNet_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd1jgQ4U3CQ6"
      },
      "source": [
        "#metrics = IR_history.keys()\n",
        "completed_epochs = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYY3bC123COy"
      },
      "source": [
        "plt.plot(range(0,completed_epochs), ResNet_history['loss'][:completed_epochs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1MLx5ui8Xew"
      },
      "source": [
        "#### TO DO\n",
        "- Create confusion matrix\n",
        "- Create scatter plots and line plots with history data\n",
        "- Solve resource problem (can't run with batches of over 200 samples atm) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6BFXjGR1MQd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7VYZyJ4_4cj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}